<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>018 - Kinesis Connector · Hazelcast Jet</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Source and Sink for Amazon Kinesis Data Streams"/><meta name="docsearch:version" content="4.5.2"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="018 - Kinesis Connector · Hazelcast Jet"/><meta property="og:type" content="website"/><meta property="og:url" content="https://jet-start.sh/"/><meta property="og:description" content="Source and Sink for Amazon Kinesis Data Streams"/><meta property="og:image" content="https://jet-start.sh/img/Hazelcast-Jet-Logo-Blue_Dark.jpg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://jet-start.sh/img/Hazelcast-Jet-Logo-Blue_Dark.jpg"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://jet-start.sh/blog/atom.xml" title="Hazelcast Jet Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://jet-start.sh/blog/feed.xml" title="Hazelcast Jet Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-158279495-1', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,500,600"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600,700,800"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/code-block-buttons.js"></script><script type="text/javascript" src="https://plausible.io/js/plausible.js" async="" defer="" data-domain="jet-start.sh"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/prism.css"/><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/logo-dark.svg" alt="Hazelcast Jet"/></a><a href="/versions"><h3>4.5.2</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/docs/4.5.2/get-started/intro" target="_self">Docs</a></li><li class=""><a href="/download" target="_self">Download</a></li><li class=""><a href="/demos" target="_self">Demos</a></li><li class=""><a href="https://github.com/hazelcast/hazelcast-jet" target="_self">GitHub</a></li><li class=""><a href="https://slack.hazelcast.com/" target="_self">Community</a></li><li class=""><a href="/blog/" target="_self">Blog</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Design Documents</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Get Started<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/get-started/intro">Introduction</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/get-started/first-job">Your First Jet Program</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/get-started/installation">Set Up a Jet Cluster</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/get-started/submit-job">Submit a Job to the Cluster</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/get-started/scale-job">Scale Your Job</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Tutorials<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/kafka">Connect to Apache Kafka</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/kinesis">Connect to Amazon Kinesis</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Change Data Capture</h4><ul><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/cdc">MySQL</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/cdc-postgres">PostgreSQL</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/cdc-join">Join</a></li></ul></div><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/map-join">Enrich Your Stream</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/windowing">Apply Windowed Aggregation</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/python">Apply a Python Function</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/spring-boot">Spring Boot Starter</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/tutorials/pulsar">Group Messages from Apache Pulsar</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Concepts<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/concepts/dag">Directed Acyclic Graph (DAG)</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/concepts/event-time">Streaming and Event Time</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/concepts/processing-guarantees">Processing Guarantees for Stateful Computation</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Programming Guide<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/pipeline">Building Pipelines</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/stateless-transforms">Stateless Transforms</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/stateful-transforms">Stateful Transforms</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/more-transforms">More Transforms</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/sources-sinks">Sources and Sinks</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/submitting-jobs">Submitting Jobs</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/data-structures">Distributed Data Structures</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/serialization">Serialization</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/error-handling">Error Handling Strategies</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/testing">Testing</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/api/spring">Spring Integration</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">SQL<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/sql/intro">Hazelcast Jet SQL</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/sql/basic-commands">SQL Statements</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/sql/ddl">DDL Statements</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/sql/job-management">Job Management</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/sql/imap-connector">IMap Connector</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/sql/file-connector">File Connector</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/sql/kafka-connector">Apache Kafka Connector</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">How-To Guides<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/stream-imap">Receive IMap Change Stream</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/observables">Receive Results on the Client</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/custom-batch-source">Add Batching to Custom Source</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/custom-stream-source">Create a Streaming Source</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/custom-sink">Create a Sink</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/custom-aggregate-operation">Build a Custom Aggregate Operation</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/operator">Install Kubernetes Operator</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/xa">Compatibility of XA Support</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/how-tos/grpc">Call gRPC Service</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Operations Guide<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/installation">Installation</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/configuration">Configuration</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/discovery">Cluster Discovery</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/cluster-sizing">Cluster Sizing</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/gc-concerns">Concerns Related to GC</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/job-management">Job Management</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/docker">Running With Docker</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/kubernetes">Deployment On Kubernetes</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/monitoring">Monitoring and Metrics</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/version-compatibility">Version Compatibility</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/operations/cdc">Change Data Capture</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Architecture<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/architecture/distributed-computing">Pipeline Execution Model</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/architecture/execution-engine">Cooperative Multithreading</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/architecture/cluster-topology">Cluster Topology</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/architecture/event-time-processing">Event Time-Based Processing</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/architecture/sliding-window">Sliding Window Aggregation</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/architecture/fault-tolerance">Fault Tolerance</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/architecture/in-memory-storage">In-Memory Storage</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Enterprise Edition<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/">Introduction</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/installation">Installation</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/management-center">Management Center</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/operator-openshift">Installation on Red Hat OpenShift</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/security">Security</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/job-update">Updating Jobs</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/lossless-restart">Lossless Cluster Restart</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/off-heap">Off-Heap Data Structures</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/enterprise/blue-green">Blue-Green Client</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Design Documents<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/">Introduction</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/docs/4.5.2/design-docs/018-kinesis-connectors">018 - Kinesis Connector</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/017-file-data-ingestion">017 - File Data Ingestion</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/016-event-reordering">016 - Avoiding Event Reordering Effects</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/015-mqtt-connector">015 - Mqtt Connector</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/014-batchstage-sort">014 - BatchStage.sort()</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/013-system-time-watermarks">013 - Resolving Sparse Events Issue with System-Time Watermarks</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/012-improved-job-resilience">012 - Improved Resilience of Fault-Tolerant Streaming Jobs</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/011-json-convenience">011 - JSON Convenience</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/010-operator-framework">010 - Kubernetes Operators</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/009-pulsar-connector">009 - Apache Pulsar Connector</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/008-stage-rebalance">008 - Rebalance Data on a Pipeline Stage</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/007-grpc-support">007 - Extended gRPC Support</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/006-declarative-serialization">006 - Declarative Serialization</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/005-cdc-sources">005 - Change Data Capture (CDC) Sources</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/004-spring-boot-starter">004 - Spring Boot Starter</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/003-elasticsearch-connector">003 - Elasticsearch Connector</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/002-job-level-serialization">002 - Job-level Serialization</a></li><li class="navListItem"><a class="navItem" href="/docs/4.5.2/design-docs/001-code-deployment-improvements">001 - Code Deployment Improvements</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/hazelcast/hazelcast-jet/edit/master/site/docs/design-docs/018-kinesis-connectors.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 id="__docusaurus" class="postHeaderTitle">018 - Kinesis Connector</h1></header><article><div><span><p><em>Since</em>: 4.4</p>
<h2><a class="anchor" aria-hidden="true" id="summary"></a><a href="#summary" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Summary</h2>
<p><a href="https://aws.amazon.com/kinesis/data-streams/">Amazon Kinesis Data
Streams</a> (KDS) is a
massively scalable and durable real-time data streaming service. As part
of the Amazon Web Services offering, KDS manages the infrastructure,
storage, networking, and configuration needed to stream your data at the
level of your data throughput. You do not have to worry about
provisioning, deployment, ongoing-maintenance of hardware, software, or
other services for your data streams. Also, Amazon Kinesis Data Streams
synchronously replicates data across three availability zones, providing
high availability and data durability.</p>
<p>The purpose of this document is to describe the implementation of
distributed Jet sources and sinks, which make it possible to read data
from and write data into Kinesis via Jet.</p>
<h2><a class="anchor" aria-hidden="true" id="key-concepts"></a><a href="#key-concepts" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Key Concepts</h2>
<p>A <strong>shard</strong> is the base throughput unit of KDS. Shards help break the
stream's data flow into independent substreams, which can be processed
in parallel. Shards preserve the order of the data items they ingest
while ordering among different shards' items is undefined. One shard
provides a capacity of 1MiB/sec data input and 2MiB/sec data output. One
shard can support up to 1000 record publications per second. You will
specify the number of shards needed when you create a data stream. For
example, you can create a data stream with two shards. This data stream
has a throughput of 2MiB/sec data input and 4MiB/sec data output and
allows up to 2000 record publications per second. You can monitor
shard-level metrics in Kinesis and add or remove shards from your data
stream dynamically as your data throughput changes by resharding the
data stream.</p>
<p>A <strong>record</strong> is the unit of data stored in Kinesis. A record is composed
of a sequence number, partition key, and data blob. Data blob is the
data of interest your data producer adds to a data stream. The maximum
size of a data blob (the data payload before Base64-encoding) is 1 MiB.</p>
<p>A <strong>partition key</strong> is used to assign records to different shards of a
data stream. Items with the same partition key always belong to the same
shard. Since shards preserve the order of the items they ingest, the
ordering of records with the same partition key is also preserved. The
partition key is specified by your data producer while adding data to
KDS.</p>
<p>A <strong>sequence number</strong> is a unique identifier for each record within its
shard. Sequence numbers are assigned by KDS when a data producer
publishes data into it. They can be used as offsets of the ordered
series of records of a shard.</p>
<h2><a class="anchor" aria-hidden="true" id="apis"></a><a href="#apis" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>APIs</h2>
<p>Amazon offers various choices of libraries that can be used to interact
with KDS:</p>
<ul>
<li><strong>Kinesis Client Library (KCL)</strong> and <strong>Kinesis Producer Library
(KPL)</strong> are high-level libraries that are easy to use because they
abstract away many concerns. They manage their threading policy, hide
away the REST-based nature of Kinesis behind asynchronous constructs,
balance load, handle failures, and react to resharding. However, all
this convenience makes them unsuitable for building Jet connectors,
where we need the most control possible to make choices that are
suitable to Jet's architecture.</li>
<li><strong>Amazon Kinesis Data Streams API</strong> via <strong>AWS SDK for Java</strong> is the
lower-level library that allows sufficient control when interacting
with Kinesis. It consists of a simple set of <a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_Operations.html">REST-based
operations</a>.
Every other concern mentioned above, when discussing the high-level
libraries, has to be handled explicitly. This is the library used in
the Jet source and sink implementations.</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="quotas"></a><a href="#quotas" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Quotas</h2>
<p>Amazon Kinesis Data Streams enforces quite a few quotas and limits,
which our sources and sinks need to comply with:</p>
<ul>
<li>A single shard can ingest up to 1 MiB of data per second (including
partition keys) or 1,000 records per second for writes.</li>
<li>The maximum size of the data payload of a record is 1 MiB.</li>
<li>The
<a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html">GetRecords</a>
operation can retrieve up to 10 MiB of data per call from a single
shard and up to 10,000 records per call.</li>
<li>Each shard can support up to 5 GetRecords operations per second.</li>
<li>Each shard can support up to a maximum total data read rate of 2 MiB
per second.</li>
<li>The
<a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html">ListShards</a>
operation has a limit of 100 transactions per second, per data stream.
Each such transaction is able to return at most 100 shards, and if the
stream has more, then multiple transactions need to be used for a full
listing. (For details, see the <a href="#discovery">discovery</a> section.)</li>
<li>The
<a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecords.html">PutRecords</a>
operation can write at most 500 records into the stream. Each record
in the request can be as large as 1MiB, up to a limit of 5MiB for the
entire request, including partition keys. Each shard can support
writes up to 1,000 records per second, up to a maximum data write
total of 1 MiB per second.</li>
<li>The
<a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStreamSummary.html">DescribeStreamSummary</a>
operation has a limit of 20 transactions per second per account. (For
details, see the <a href="#adaptive-throughput">adaptive throughput</a> section.)</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="source"></a><a href="#source" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Source</h2>
<p>The Kinesis source is a <em>streaming</em>, <em>distributed</em>, and <em>fault-tolerant</em>
data source for Jet. It supports both the <em>at-least-once</em> and
<em>exactly-once</em> <a href="/docs/4.5.2/architecture/fault-tolerance#processing-guarantee-is-a-shared-concern">processing
guarantees</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="distribution"></a><a href="#distribution" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Distribution</h3>
<p>Being a distributed source, it has multiple instances running in each
Jet cluster member. Each instance is responsible for reading from zero,
one or more KDS <a href="#shard">shards</a>. Each shard will be read by exactly one
source instance, the assignment is deterministic.</p>
<p>Record keys, or partition keys as Kinesis calls them, are Unicode
strings, with a maximum length limit of 256 characters. The stream uses
the MD5 hash function to map these strings to 128-bit integer values.
The range of these values is thus [0 .. 2^128). Each Kinesis shard has a
continuous chunk of this range assigned to it, called the shard's hash
range. The stream assigns a record to a shard if the record's partition
key hashes into the shard's range.</p>
<p>In the Jet Kinesis source, we use similar logic for assigning shards to
source instances. Each of our sources gets a part of the hash range
assigned to it. We say that a source owns a specific shard if and only
if the shard's hash range's starting point is inside the source's hash
range. Any similar range matching logic would work, as long as it's
non-ambiguous.</p>
<h3><a class="anchor" aria-hidden="true" id="discovery"></a><a href="#discovery" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Discovery</h3>
<p>Reading records from shards assigned to them is only a part of the
responsibility of sources. Sources also need a way to discover currently
active shards in the stream to take responsibility for them. Moreover,
this discovery process can't just happen once, on start-up, because
shards are dynamic, shards can be closed, and new shards can pop up at
any time. For details, see the <a href="#resharding">resharding section</a>.</p>
<p>Continuously monitoring the set of active shards in the stream is the
responsibility of <strong>one</strong> of the local source instances in each Jet
cluster member. This is an optimization. If all sources would run the
discovery, they would still obtain the same data, just with a multiplied
effort and cost. Monitoring means continuously polling the stream for
the list of all shards in it.</p>
<p>Monitoring needs to take care not to cross the rate limit imposed by
Kinesis on this operation. For details, see the <a href="#quotas">quotas
section</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="resharding"></a><a href="#resharding" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Resharding</h3>
<p>Kinesis supports resharding, which lets you adjust the number of shards
in your stream to adapt to changes in data flow rate through the stream.
(Amazon charges on a per-shard basis, that's why it's desirable to have
the smallest amount of shards possible.)</p>
<p>There are two types of resharding operations: shard <strong>split</strong> and shard
<strong>merge</strong>. In a shard split, you divide a single shard into two adjacent
shards. In a shard merge, you combine two adjacent shards into a single
shard. By &quot;adjacent&quot;, we mean that one's hash range starts where the
other one's ends.</p>
<p>Splitting increases the number of shards in your stream and therefore
increases the data capacity (and cost) of the stream. Similarly, merging
reduces the number of shards in your stream and therefore decreases the
data capacity (and cost).</p>
<p>Resharding is always pairwise in the sense that you cannot split into
more than two shards in a single operation, and you cannot merge more
than two shards in a single operation. The shard or pair of shards that
the resharding operation acts on are called parent shards. The shard or
pair of shards that result from the resharding operation are called
child shards.</p>
<p>When child shards, resulting from a split or merge, activate, their
parents get deactivated and will no longer get data inserted into them.
From that point onward, data goes into the children.</p>
<h3><a class="anchor" aria-hidden="true" id="read-order"></a><a href="#read-order" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Read Order</h3>
<p>Resharding does not suspend the stream's dataflow, while it's going on.
Data continues to be ingested into the stream, and at some point, it
just stops being put into the parent shards and starts being put into
the child shards.</p>
<p>The Kinesis Jet source would need to make sure that it finishes reading
from parents before reading from their children. However, this is not
possible since the children might end up being owned by an entirely
different instance of the source than their parents (for example, in a
split), possibly located in an entirely different Jet cluster member.</p>
<p>Moreover, it's not enough to finish reading from the parent before
reading from the children. Even if that was achieved, data from parents
might overtake data from children further down the Jet pipeline, simply
because it's a parallel flow. A Kinesis source would need to make sure
that it has read all data from the parents and that data has fully
passed through the Jet pipeline before starting to read from the
children. Only then it could provide the same ordering as KDS while
resharding.</p>
<p>This is currently not possible in Jet. Hopefully, future versions will
address the problem. Users of the Kinesis source need to be aware that
some data reordering might occur on resharding and try to time their
resharding activities, if possible, to utilize lulls in the data flow.</p>
<h3><a class="anchor" aria-hidden="true" id="fault-tolerance"></a><a href="#fault-tolerance" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fault Tolerance</h3>
<p>The Kinesis Jet source supports pipelines with both at-least-once and
exactly-once processing guarantees. It achieves this by saving KDS
offsets into its snapshots and starting the reading from saved offsets
when restarted.</p>
<p>The offsets are saved on a per-shard basis, and on restart, each source
instance receives all saved offsets for all shards, so it can function
properly regardless of how shards are assigned to sources after the
restart.</p>
<h3><a class="anchor" aria-hidden="true" id="watermarks"></a><a href="#watermarks" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Watermarks</h3>
<p>The Kinesis source can provide native timestamps because the <a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_Record.html">record
data
structure</a>
has a field that can be turned towards this purpose
(<code>ApproximateArrivalTimestamp</code>). However, it should be pointed out that
these watermarks are &quot;native&quot; only from Jet's point of view. They are
KDS ingestion times, i.e., whenever a KDS producer managed to push said
record into the data stream. We have no way of knowing what's the real
event time of a record.</p>
<p>Watermarks are also saved to and recovered from snapshots.</p>
<h3><a class="anchor" aria-hidden="true" id="metrics"></a><a href="#metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Metrics</h3>
<p>When receiving record batches, the <a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html#API_GetRecords_ResponseSyntax">data
structure</a>
contains a field called <code>MillisBehindLatest</code> defined as following:</p>
<blockquote>
<p>The number of milliseconds the GetRecords response is from the
stream's tip, indicating how far behind the current time the consumer
is. A value of zero indicates that record processing caught up, and
there are no new records to process at this moment.</p>
</blockquote>
<p>This value can be useful for monitoring, so the sources publish it as a
per-processor metric.</p>
<h3><a class="anchor" aria-hidden="true" id="code-example"></a><a href="#code-example" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Code Example</h3>
<p>A typical example of setting up a Kinesis source in Jet would look like
this:</p>
<pre><code class="hljs css language-java"><span class="token class-name">KinesisSources</span><span class="token punctuation">.</span><span class="token function">kinesis</span><span class="token punctuation">(</span><span class="token string">"myStream"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">withRegion</span><span class="token punctuation">(</span><span class="token string">"us-east-1"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">withEndpoint</span><span class="token punctuation">(</span><span class="token string">"http://localhost:12345"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">withCredentials</span><span class="token punctuation">(</span><span class="token string">"accesskey"</span><span class="token punctuation">,</span> <span class="token string">"secretkey"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">withRetryStrategy</span><span class="token punctuation">(</span><span class="token class-name">RetryStrategies</span><span class="token punctuation">.</span><span class="token function">indefinitely</span><span class="token punctuation">(</span><span class="token number">250</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>The only mandatory property is the Kinesis <code>stream name</code>. The others are
optional and can be specified via a fluent builder.</p>
<p>If <code>region</code> is not specified, then <em>us-east-1</em> will be used by default.</p>
<p>If <code>endpoint</code> is not specified, then the region's default endpoint will
be used.</p>
<p>If <code>credentials</code> aren't specified, then the <a href="https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html#credentials-default">Default Credential Provider
Chain</a>
will be followed.</p>
<p>If <code>retry strategy</code> is not specified, then a default will be used
(defined by us - retry indefinitely, with exponential backoff limited to
a maximum of 3 seconds). A source's retry strategy applies to failures
of reading records from or listing shards of a stream.</p>
<p>The actual source created will be of type
<code>StreamSource&lt;Map.Entry&lt;String, byte[]&gt;&gt;</code>, so basically a stream of
partition key - record data blob pairs.</p>
<h2><a class="anchor" aria-hidden="true" id="sink"></a><a href="#sink" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sink</h2>
<p>The Kinesis sink is a <em>distributed</em>, <em>fault-tolerant</em> data sink for Jet.
It supports both <em>streaming</em> and <em>batching</em> pipelines. The
fault-tolerance guarantee it can offer is only <em>at-least-once</em> since
Kinesis does not offer transaction support.</p>
<h3><a class="anchor" aria-hidden="true" id="distribution-1"></a><a href="#distribution-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Distribution</h3>
<p>Being a distributed sink, it has multiple instances running in each Jet
cluster member. When used in a pipeline, this sink forces its incoming
edges to be <em>distributed</em> and <em>partitioned</em>. The partition keys used by
the edges are the same as the Kinesis <a href="#partition-key">partition keys</a>.
This ensures that all data with the same partition key will end up in
the same global sink instance and the same shard.</p>
<h3><a class="anchor" aria-hidden="true" id="flow-control"></a><a href="#flow-control" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Flow Control</h3>
<p>Writing data into a Kinesis Data Stream is governed by multiple
limitations:</p>
<ul>
<li>no more than 500 records can be written in one batch</li>
<li>each record must contain no more than 1M of data</li>
<li>each batch must contain no more than 5M of data</li>
<li>each shard can ingest no more than 1,000 records per second</li>
</ul>
<p>While most of these limitations are simple to enforce, the shard
ingestion rate is not. Different partition keys get assigned to a shard
based on a hashing function, so partition keys going into the same shard
can be written by different sink instances. Currently, Jet has no
capability for computing and coordinating such a per-shard rate among
all its distributed sink instances.</p>
<p>The sink takes a different approach to comply with this limitation. It
allows for the rate to be tripped (i.e., it doesn't attempt to prevent
it from happening), but once it gets tripped, sinks try to slow down the
amount of data they write to keep the rate violation as an occasional,
rare event and not a continuous storm.</p>
<p>The source achieves this flow control in two ways:</p>
<ul>
<li>by decreasing the send batch size; the default is the maximum of 500,
which it will reduce, if necessary, to as low as 10 records/batch</li>
<li>by adding a delay between two subsequent send actions (which can be as
little as 100ms, a reasonable value in case of Kinesis and as much as
10 seconds, which is a lot, but would occur only in an unreasonably
sized stream, as far as shard count is concerned - ultimately the
owner of the stream is responsible for setting up enough shards to be
able to handle his data rates)</li>
</ul>
<p>The flow control process is <em>adaptive</em> in the sense that:</p>
<ul>
<li>it kicks in only when batches start failing due to shard ingestion
rates being tripped</li>
<li>as long as failures repeat, it keeps quickly increasing the sleep
delays to stop them from happening</li>
<li>once failures stop, it slowly decreases the sleep delays until they
are eliminated (i.e., the data volume spike was only temporary) or
until failures start happening again</li>
</ul>
<p>Under normal circumstances, if there are enough shards in the stream and
their data ingestion rate covers the data flow, this whole flow control
process stays shut off. The sink publishes data with the lowest possible
latency.</p>
<h3><a class="anchor" aria-hidden="true" id="discovery-1"></a><a href="#discovery-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Discovery</h3>
<p>As we've seen in the <a href="#flow-control">flow control</a> section, one element
used to control the throughput is batch size. Under normal conditions,
the sink uses the default/maximum batch size of 500. When flow control
kicks in, a new batch size is picked as a function of the number of open
shards in the stream.</p>
<p>For this to happen, the sinks need to have a relatively up-to-date
information about the number of open shards. The sink achieves this by
using a mechanism very similar to the <a href="#discovery">discovery process employed by the
source</a>. The only real difference is that the sinks use the
<a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStreamSummary.html">DescribeStreamSummary</a>
operation instead of the
<a href="https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html">ListShards</a>
one.</p>
<h3><a class="anchor" aria-hidden="true" id="write-order"></a><a href="#write-order" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Write Order</h3>
<p>Under normal circumstances, the Kinesis sink preserves the order of
items belonging to the same partition key. However, when the <a href="#flow-control">flow
control</a> mechanism kicks in, the ordering might be lost
on occasion.</p>
<p>This fact originates in the way how KDS handles shard ingestion rate
violations. When KDS receives a batch to be ingested, it processes each
item in it one by one, and if some fail, it doesn't stop processing the
batch. The result is that some items from a batch get rejected, some get
ingested, but in a random manner. The sink does resend the non-ingested
item, they won't get lost, but there is nothing it can do to preserve
the initial ordering.</p>
<p>The advice we can give to Kinesis sink users, if they care about
ordering at all, is to try to have enough shards to accommodate even
occasional spikes in their data rate and to make sure that their
partition keys are spread out adequately over all shards.</p>
<h3><a class="anchor" aria-hidden="true" id="fault-tolerance-1"></a><a href="#fault-tolerance-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fault Tolerance</h3>
<p>Since there is no transaction support in Kinesis, the sink can't support
exactly-once delivery. It can, however, support at-least-once
processing. It does that by ensuring it flushes all data it has taken
ownership of (taken from the <code>Inbox</code> is the more accurate &quot;dev-speak&quot;)
out to Kinesis, before saving its snapshots.</p>
<p>A further reason why exactly-once support is not possible is the API
used to implement the sink, the AWS SDK itself. It has internal retry
mechanisms, which can lead to duplicate publishing of records. For
details, see the <a href="https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-duplicates.html#kinesis-record-processor-duplicates-producer">relevant parts of its
documentation</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="metrics-1"></a><a href="#metrics-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Metrics</h3>
<p>Two metrics that should be useful to populate on a per-sink basis are
parameters related to <a href="#flow-control">flow control</a>:</p>
<ul>
<li>batch size</li>
<li>sleep between two consecutive send attempts</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="code-example-1"></a><a href="#code-example-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Code Example</h3>
<p>A typical example of setting up a Kinesis sink in Jet would look like
this:</p>
<pre><code class="hljs css language-java"><span class="token class-name">KinesisSinks</span><span class="token punctuation">.</span><span class="token function">kinesis</span><span class="token punctuation">(</span><span class="token string">"myStream"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">withRegion</span><span class="token punctuation">(</span><span class="token string">"us-east-1"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">withEndpoint</span><span class="token punctuation">(</span><span class="token string">"http://localhost:12345"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">withCredentials</span><span class="token punctuation">(</span><span class="token string">"accesskey"</span><span class="token punctuation">,</span> <span class="token string">"secretkey"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">withRetryStrategy</span><span class="token punctuation">(</span><span class="token class-name">RetryStrategies</span><span class="token punctuation">.</span><span class="token function">indefinitely</span><span class="token punctuation">(</span><span class="token number">250</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>The properties here work exactly like the ones for the
<a href="#code-example">source</a>. What's worth noting, though, is that this
version is a simplified form. It is able to accept only input items of
the form of <code>Map.Entry&lt;String, byte[]&gt;</code> (so partition key - data blob
pairs).</p>
<p>A more generic form, which can accept any item stream, is of the form:</p>
<pre><code class="hljs css language-java"><span class="token class-name">KinesisSinks</span><span class="token punctuation">.</span><span class="token function">kinesis</span><span class="token punctuation">(</span>
  <span class="token annotation punctuation">@Nonnull</span> <span class="token class-name">String</span> stream<span class="token punctuation">,</span>
  <span class="token annotation punctuation">@Nonnull</span> <span class="token class-name">FunctionEx</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> keyFn<span class="token punctuation">,</span>
  <span class="token annotation punctuation">@Nonnull</span> <span class="token class-name">FunctionEx</span><span class="token operator">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">></span> valueFn
<span class="token punctuation">)</span>
</code></pre>
<p>It has two more mandatory parameters:</p>
<ul>
<li>a <code>key function</code> that specifies how to compute the partition key from
an input item</li>
<li>a <code>value function</code> that specifies how to compute the data blob from an
input item</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="testing"></a><a href="#testing" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Testing</h2>
<p>Both the Kinesis source and sink can be covered by integration tests in
which the AWS backend is mocked with the help of
<a href="https://github.com/localstack/localstack">LocalStack</a> and
<a href="https://www.testcontainers.org/">Testcontainers</a>.</p>
<p>This mock is pretty reliable, with only small disadvantages. One of them
is that it doesn't enforce the intake rate of shards, so we can't write
tests to verify the sink's flow control behavior when trying to publish
more data than the stream can ingest. Another disadvantage is that it
ignores credentials (accepts anything), so we can't test behavior when
credentials are incorrect. These scenarios can, however, be tested
manually on the real AWS backend.</p>
<h2><a class="anchor" aria-hidden="true" id="future-improvements"></a><a href="#future-improvements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Future Improvements</h2>
<p>One extra Kinesis connector we could add to Jet in the future would be a
version of the source which supports <em>enhanced fan-out</em>. Such a Kinesis
consumer is different in two ways: it has dedicated throughput, and it
gets data pushed to it, doesn't have to poll. Implementing such a source
in future versions, though, needs to be motivated with concrete needs.</p>
<p>Another future improvement would be adding a generic mechanism to Jet,
which would enable us to solve the <a href="#read-order">ordering problem when
resharding</a>. This would be some kind of signaling mechanism
we could use in a Kinesis source to check that certain previously
dispatched items have cleared the entire pipeline. It's not clear how
exactly this would work and if it will be implemented at all.</p>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/4.5.2/design-docs/index"><span class="arrow-prev">← </span><span>Introduction</span></a><a class="docs-next button" href="/docs/4.5.2/design-docs/017-file-data-ingestion"><span>017 - File Data Ingestion</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#summary">Summary</a></li><li><a href="#key-concepts">Key Concepts</a></li><li><a href="#apis">APIs</a></li><li><a href="#quotas">Quotas</a></li><li><a href="#source">Source</a><ul class="toc-headings"><li><a href="#distribution">Distribution</a></li><li><a href="#discovery">Discovery</a></li><li><a href="#resharding">Resharding</a></li><li><a href="#read-order">Read Order</a></li><li><a href="#fault-tolerance">Fault Tolerance</a></li><li><a href="#watermarks">Watermarks</a></li><li><a href="#metrics">Metrics</a></li><li><a href="#code-example">Code Example</a></li></ul></li><li><a href="#sink">Sink</a><ul class="toc-headings"><li><a href="#distribution-1">Distribution</a></li><li><a href="#flow-control">Flow Control</a></li><li><a href="#discovery-1">Discovery</a></li><li><a href="#write-order">Write Order</a></li><li><a href="#fault-tolerance-1">Fault Tolerance</a></li><li><a href="#metrics-1">Metrics</a></li><li><a href="#code-example-1">Code Example</a></li></ul></li><li><a href="#testing">Testing</a></li><li><a href="#future-improvements">Future Improvements</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><div style="text-align:left"><a href="/" class="nav-home"><img src="/img/logo-light.svg" alt="Hazelcast Jet" width="200" height="40"/></a><div style="margin-left:12px"><a class="github-button" href="https://github.com/hazelcast/hazelcast-jet" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star On GitHub</a></div></div><div><h5>Docs</h5><a href="/docs/get-started/intro">Get Started</a><a href="/docs/concepts/dag">Concepts</a><a href="/docs/tutorials/kafka">Tutorials</a><a href="/docs/architecture/distributed-computing">Architecture</a><a href="/docs/operations/installation">Operations Guide</a><a href="/docs/enterprise">Enterprise Edition</a></div><div><h5>Community</h5><a href="https://groups.google.com/forum/#!forum/hazelcast-jet" target="_blank" rel="noreferrer noopener">Google Groups</a><a href="http://stackoverflow.com/questions/tagged/hazelcast-jet" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://slack.hazelcast.com">Slack</a></div><div><h5>Latest From the Blog</h5><a href="/blog/2023/06/14/jet-engine-in-hazelcast">Jet engine lives on in Hazelcast 5.x</a><a href="/blog/2021/04/21/jet-45-is-released">Jet 4.5 Released</a><a href="/blog/2021/03/17/billion-events-per-second">Billion Events Per Second with Millisecond Latency: Streaming Analytics at Giga-Scale</a><a href="/blog/2021/02/03/jet-44-is-released">Jet 4.4 Released</a><a href="/blog/2020/10/23/jet-43-is-released">Jet 4.3 Released</a></div><div><h5>More</h5><a href="https://github.com/hazelcast/hazelcast-jet">GitHub Project</a><a href="http://hazelcast.com/company/careers/">Work at Hazelcast</a><a href="/license">License</a></div></section><section class="copyright">Copyright © 2023 Hazelcast Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '79d1e4941621b9fd761d279d4d19ed69',
                indexName: 'hazelcast-jet',
                inputSelector: '#search_input_react',
                algoliaOptions: {"facetFilters":["language:en","version:4.5.2"]}
              });
            </script></body></html>